\newpage
\chapter{Модели исследования и результаты} \label{ch4}

% не рекомендуется использовать отдельную section <<введение>> после лета 2020 года
%\section{Введение} \label{ch4:intro}

В данной главе будут рассмотрены  исследуемые модели машинного обучения. Результаты их работы и сравнение рекомендаций полученных в результате работы рассмотренных моделей.

	
\section{Предообучение признаков объекта} \label{ch4:sec1}

В данной модели моделируется условное распределение вероятностей признаков, находящихся в соседних объектах пользовательских сессий. 


Признаки, имеющие шкалу абсолютных величин, разбивались на перцентили, данная эвристика исходила из того, что в задачах рекомендации пользователи в общей совокупности делятся на некоторые подмножества, 
которые обуславливаются общими характеристиками по некоторым признакам. То есть множества сущностей всех признаков мы разбивали на категории.


Каждый признак имел векторное представление размером $min(n / 2 + 1, 50)$, $n$ - мощность множества сущностей признака объекта.
Данная эмпирическая закономерность была выведена путем поиска по сетке, описанная в \cite{sizeEmbedding}.


После чего полученные вектора сущностей признаков конкатенировались в соответствие с матрицей объект-признак. 
Тем самым мы получем векторное представление для каждого объекта.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]
    {my_folder/images/tensors.png}
    \caption{Архитектура модели предобучения признаков}
    \label{fig:tensors}
\end{figure}


Полученные вектора признаков будут использоваться как новые признаки для следующих моделей. 

График функции потерь при обучении модели для 4 признаков: 

\section{Использование полносвязных слоев} \label{ch4:sec2}

Данная модель по своей структуре является классификатором.

Его идея заключается в том, чтобы найти взаимосвязь между предобученными признаками объекта и представить в более меньшей размерности.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]
    {my_folder/images/neural_network.png}
    \caption{Архитектура нейронной сети}
    \label{fig:neural_network}
\end{figure}

\subsection{Метод обучения} \label{ch4:sec2:sec1}

Для обучения модели необходимо выбрать пару из нашей выборки, которая входит в сессию пользователя. 
К данной паре необходимо подобрать некоторое количество негативных примеров. Это случайные объекты из нашей выборки.

Затем прогоняем через сеть пару объектов, а также негативные примеры. После чего считаем скалярное произведение между парой и негативными элементами.
Выбираем 100 элементов с самым большим значением скалярного произведения из множества негативных примеров. И считаем функцию потерь - cross entropy loss.

\begin{equation}
    loss(x, class) = -\log (\frac{\exp (x[class])}{\sum (\exp (x[j]))} ) = -x[class] + \log (\sum(exp(x[j])))
\end{equation}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=\textwidth]
    {my_folder/images/train.png}
    \caption{Структура тренировки модели}
    \label{fig:train}
\end{figure}

\section{Модифицированная модель с полносвязными слоями} \label{ch4:sec3}

В данной модели усовершенствование работы алгоритма заключается из того, что для полученных вектора уже хранят в себе семантический смысл, 
поэтому для каждой сессии пользователя, используются алгебраические операции над векторами объектов. То есть теперь данными являются не пара похожих объектов, а пара: среднее векторов между последовательностью объектов входящих в одну сессию и следующим за ними объектом из этой же сессии. 

\section{Ансамблирование алгоритмов обучения} \label{ch4:sec4}

В данной модели моделируется условное распределение вероятностей объектов, находящихся в соседних объектах пользовательских сессий.
При этом имея в наличии уже предобученные вектора признаков.

Данное распределение моделировалось на таком же алгоритме word2vec, как и для обучения признаков объектов.
Отличие заключается лишь в том, что изначальные вектора были получены в результате конкатенации векторов-признаков, а не инициализации случайным шумом.

\section{Выбор метрики} \label{ch4:sec5}
В результате применение вышеописанного алгоритма, мы сможем получить векторное представление объектов более низкой размерности,
 при этом данный алгоритм смог сохранить семантику объектов в векторном представление.
  Эта семантика выражается через отношение близости объектов. Наиболее схожие объекты между собой находятся близко в построенном векторном пространстве.
   Эта идея является ключевой для построения рекомендательной системы. \\
В статье  \cite{dist} описываются сравниваются различные оценки близости такие как: евклидово расстояние, косинусная близость, метрика Манхэттена, расстояние Бхаттачарья, расстояние Хеллингера, дивергенция Кульбака-Лейблера. В результате экспериментов косинусная близость показала наилучший результат. \\
 
\[
\displaystyle {\text{similarity}}=\cos(\theta )={\mathbf {A} \cdot \mathbf {B}  \over \|\mathbf {A} \|\|\mathbf {B} \|}={\frac {\sum \limits _{i=1}^{n}{A_{i}B_{i}}}{{\sqrt {\sum \limits _{i=1}^{n}{A_{i}^{2}}}}{\sqrt {\sum \limits _{i=1}^{n}{B_{i}^{2}}}}}}
\]

\section{Результаты моделей} \label{ch4:sec6}

\subsection{Графики функции потерь} \label{ch4:sec6:sec1}

\begin{enumerate}
    \item Векторное представление признаков объекта.
    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.5]
        {my_folder/images/lotarea_loss.png}
        \caption{Функция потерь для площади земельного участка}
        \label{fig:lotarea_loss}
    \end{figure}

    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.5]
        {my_folder/images/live_value.png}
        \caption{Функция потерь для жилплощади}
        \label{fig:live_value}
    \end{figure}

    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.5]
        {my_folder/images/kitchen_loss.png}
        \caption{Функция потерь для площади кухни}
        \label{fig:kitchen_space}
    \end{figure}

    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.5]
        {my_folder/images/year.png}
        \caption{Функция потерь для года постройки}
        \label{fig:year}
    \end{figure}

    Можно увидеть, что обучение на всех признаков достигает некоторого оптимума.

    \item Модель с полносвязными слоями

    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.8]
        {my_folder/images/neural.png}
        \caption{Функция потерь модели с полносвязными слоями}
        \label{fig:neural}
    \end{figure}

    \item Модифицированная модель с полносвязными слоями
    
    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.8]
        {my_folder/images/update_neural.png}
        \caption{Функция потерь модели с полносвязными слоями}
        \label{fig:update_neural}
    \end{figure}

    \item Ансамблирование алгоритмов обучения
    

    \begin{figure}[!ht]
        \centering
        \includegraphics[scale=0.8]
        {my_folder/images/stacking.png}
        \caption{Функция потерь для ансамбля моделей}
        \label{fig:stacking}
    \end{figure}

    Как можно заметить модель быстро переобучается и теряет "знания" о предобученных признаках.

\end{enumerate}

\subsection{Поиск похожих объектов}

В данном исследовании будет рассмотрено, как алгоритм хорошо представляет объекты в векторном пространстве, то есть
располагает похожие объекты близко. Для этого будем строить рекомендации для некоторых случайно выбранных объектов, которые относится к разным категориям, таким как:

\begin{itemize}
    \item Продажа квартиры
    \item Аренда квартиры
    \item Аренда дома
\end{itemize} 


        \begin{figure}[ht!]
            \centering
            \includegraphics[width=\textwidth]
            {my_folder/images/tensor_pokupka.png}
            \caption{Рекомендация векторного представления признаков для продажи квартиры}
            \label{fig:tensor_pokupka}
        \end{figure}

        \newpage

        \begin{figure}[ht!]
            \centering
            \includegraphics[width=\textwidth]
            {my_folder/images/tensor_arenda.png}
            \caption{Рекомендация векторного представления признаков для аренды квартиры}
            \label{fig:tensor_arenda}
        \end{figure}
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=\textwidth]
            {my_folder/images/tensor_house.png}
            \caption{Рекомендация векторного представления признаков для аренды загородного дома}
            \label{fig:tensor_house}
        \end{figure}

        \begin{figure}[ht!]
            \centering
            \includegraphics[width=\textwidth]
            {my_folder/images/neural_pokupka.png}
            \caption{Рекомендация модели с полносвязными слоями для продажи квартиры}
            \label{fig:neural_pokupka}
        \end{figure}
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=\textwidth]
            {my_folder/images/neural_arenda.png}
            \caption{Рекомендация модели с полносвязными слоями для аренды квартиры}
            \label{fig:neural_arenda}
        \end{figure}
        \begin{figure}[ht!]
            \centering
            \includegraphics[width=\textwidth]
            {my_folder/images/neural_house.png}
            \caption{Рекомендация модели с полносвязными слоями для аренды загородного дома}
            \label{fig:neural_house}
        \end{figure}

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=\textwidth]
        {my_folder/images/mod_pokupka.png}
        \caption{Рекомендация модифицированной модели с полносвязными слоями для продажи квартиры}
        \label{fig:mod_pokupka}
    \end{figure}
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=\textwidth]
        {my_folder/images/mod_arenda.png}
        \caption{Рекомендация модифицированной модели с полносвязными слоями для аренды квартиры}
        \label{fig:mod_arenda}
    \end{figure}
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=\textwidth]
        {my_folder/images/mod_house.png}
        \caption{Рекомендация модифицированной модели с полносвязными слоями для аренды загородного дома}
        \label{fig:mod_house}
    \end{figure}

    \begin{figure}[ht!]
        \centering
        \includegraphics[width=\textwidth]
        {my_folder/images/2vec_pokupka.png}
        \caption{Рекомендация ансамбля моделей для продажи квартиры}
        \label{fig:2vec_pokupka}
    \end{figure}
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=\textwidth]
        {my_folder/images/2vec_arenda.png}
        \caption{Рекомендация ансамбля моделей для аренды квартиры}
        \label{fig:2vec_arenda}
    \end{figure}
    \begin{figure}[ht!]
        \centering
        \includegraphics[width=\textwidth]
        {my_folder/images/2vec_house.png}
        \caption{Рекомендация ансамбля моделей для аренды загородного дома}
        \label{fig:2vec_house}
    \end{figure}

% Модели с полносвязными слоями показались адекватны данным, также можно заметить и семантическую связь между элементами рекомендацией, это исходит из того,
% что модель выдает рекомендации основанные на характеристиках объектов и в последнюю очередь опирается на расстояние между интересующим объектом.

% Модель состоящая только из предобученных признаков вызывает сомнения, так как результатом поиска ближайших соседей является просто подбором близких по характеристикам объектам.  

% Модель использующая ансамбль - показала наихудший результат. Рекомендации - никак невозможно интерпретировать. 

\newpage
\newpage
\subsection{Кластеризация}

В данной секции экспериментов было исследовано выделение кластеров из построенного векторного пространства.
Было выбрано первые 1000 пользовательских взаимодействий (объектов), и на векторном представлении данных объектов выполнялся алгоритм кластеризации - K-Means\cite{likas2003global}
Так как алгоритм кластеризации запускался с фиксированными параметрами, но с разными векторными пространствами, то далее для интерпретации будет использоваться кластер под номером 5. 

Чтобы оценивать качество кластеризации при одних и тех же параметров, я использовал Силуэт (англ. Silhouette) \cite{sil}

\begin{equation}
    Sil(С) = \dfrac{1}{N} \sum_{c_k \in C} \sum_{x_i \in c_k} \dfrac{ b(x_i, c_k) - a(x_i, c_k) }{ max \{ a(x_i, c_k), b(x_i, c_k) \}  }
\end{equation}

Чем ближе данная оценка к 1, тем лучше.

\paragraph{Предобученные признаки}
Элементы кластера являются интерпретируемыми. Можно сказать, что в данный кластер попали те объекты, которые находятся в исторических районах города и имеют ремонт жилища.

$Sil(C) = 0.065$

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.7]
    {my_folder/images/tensor_rock.png}
    \caption{График каменистой осыпи для определения числа кластеров}
    \label{fig:tensor_rock}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.7]
    {my_folder/images/tensor_img.png}
    \caption{Представление кластеризации 1000 объектов при помощи PCA\cite{pca}}
    \label{fig:tensor_img}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]
    {my_folder/images/tensor_cluster.png}
    \caption{Элементы кластера}
    \label{fig:tensor_cluster}
\end{figure}

\newpage
\paragraph{Модель с полносвязными слоями}
Представление пространства при помощи PCA при использование данной модели, дает более равномерное покрытие пространства точками.
Интерпретация кластера в данном случае является не столь тривиальной, но логика все равно прослеживается. Можно сказать, что в данном кластере сосредоточены аренда квартир в определенной ценовой категории. 

$Sil(C) = 0.053$

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.7]
    {my_folder/images/neural_rock.png}
    \caption{График каменистой осыпи для определения числа кластеров}
    \label{fig:neural_rock}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.7]
    {my_folder/images/neural_img.png}
    \caption{Представление кластеризации 1000 объектов при помощи PCA\cite{pca}}
    \label{fig:neural_img}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]
    {my_folder/images/neural_cluster.png}
    \caption{Элементы кластера}
    \label{fig:neural_cluster}
\end{figure}

\newpage
\paragraph{Модифицировання модель с полносвязными слоями}
В данном случае, полученное векторное представление не такое равномерное как у обычной модели с полносвязными слоями, оно похоже на пространство векторов предобученных признаков объекта.
Кластер также вызывает трудности при интерпретации, но общее сходство у объектов найти можно.

$Sil(C) = 0.056$

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.7]
    {my_folder/images/mod_rock.png}
    \caption{График каменистой осыпи для определения числа кластеров}
    \label{fig:mod_rock}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[scale=0.7]
    {my_folder/images/mod_img.png}
    \caption{Представление кластеризации 1000 объектов при помощи PCA\cite{pca}}
    \label{fig:mod_img}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=\textwidth]
    {my_folder/images/mod_cluster.png}
    \caption{Элементы кластера}
    \label{fig:mod_cluster}
\end{figure}
\FloatBarrier % заставить рисунки и другие подвижные (float) элементы остановиться

\FloatBlock
\section{Выводы} \label{ch4:conclusion}

Исходя из проделанных экспериментов можно сделать вывод о том, что рассмотренные модели, кроме модели, использующая ансамбль, адекватны данным.
Косинусная мера в построенных векторных пространствах дает интерпретируемые рекомендации. 

Модель с полносвязными слоями исходя из перекрестной проверки дает лучшие рекомендации, а также более равномерно заполняет векторное пространство объектами.
Модификация этой модели не привнесла никаких изменений, а лишь усложнила интерпретацию алгоритмов кластеризации. 

Модель основанная на предобученных признаках также дает, адекватные рекомендации объектов. 

Модель, основанная на ансамбле моделей, показала наихудший результат. Исходя из графика функции потерь, было видно, как модель быстро переобучается и теряет связь с изначальными характеристиками объектов, и выучивает лишь их ранги в пользовательской сессии. 


%% Вспомогательные команды - Additional commands
%
%\newpage % принудительное начало с новой страницы, использовать только в конце раздела
%\clearpage % осуществляется пакетом <<placeins>> в пределах секций
%\newpage\leavevmode\thispagestyle{empty}\newpage % 100 % начало новой страницы